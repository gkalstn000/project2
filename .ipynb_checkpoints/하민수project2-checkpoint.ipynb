{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Part1] 서술형 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 모델의 과대적합, 과소적합, 일반화의 정의를 서술하고 수학적 예제를 들어 설명하시오.\n",
    "\n",
    "\n",
    "### 과대적합\n",
    "* 가진 정보를 모두 사용하여 너무 복잡한 모델을 만드는 것\n",
    "* 과대적합 모델은 훈련 데이터셋에 잘 맞춰져 새로운 데이터를 잘 평가하지 못함\n",
    "* 예를들어 회귀 문제에서 데이터 포인트가 10개가 주어졌다면, 과대적합은 10개중 과하게 다수의 데이터 포인트에 맞춰서 모델을 만드는 것이다. 10개중 7개의 데이터 포인트에 맞춘다면 7차 다항식 모델이 만들어진다 . 그렇게되면 모델의 복잡도가 증가하고 데이터포인트 사이사이의 모델값의 분산이 커지게되어 새로운 데이터 포인트에대한 예측오차가 커지게된다.\n",
    "### 과소적합\n",
    "* 모델의 복잡도가 너무 낮아, 데이터의 특성이 모델에 잘 반영되지 않음\n",
    "* 훈련세트에도 낮은 정확도가 나올 확률이 높다.\n",
    "* 특성 수와 데이터 샘플 갯수를 늘려야 한다.\n",
    "* 특성수를 늘리는 방법은 기존의 특성들을 조합하여 새로운 특성들을 만드는 방법이있다. 그중 하나로 polynomial 방법은 m개의 특성(x_1, x_2, ..., x_n)을 2차형식으로 조합해 기존 특성뒤에 x_1^2, x_1x_2, x_1x_3, ..., x_n^2으로 총 n^n 개의 특성을 늘린뒤, PCA기법으로 특성수를 추출해 학습 시킬 수 있다.\n",
    "* 샘플수를 늘리는 방법은 scikitlearn 라이브러리 안의 oversampling의 여러기법중 적절한 것을 선택해 샘플의 갯수를 늘릴 수 있다.\n",
    "### 일반화\n",
    "* 과대적합과 과소적합의 절충안으로서 training data와 test data의 성능 최적점을 찾는 것이 일반화다. 어느 한쪽으로 치우쳐지지 않게끔 적절한 선에서 훈련을 중단하거나, 정규화를 해주어 파라미터값을 규제하는 방법이 있다.\n",
    "* 정규화는 파라미터값에 규제를 가하는 것인데 특정 feature가 다른 feature들을 지배하는 것을 막는 기법으로, 매 훈련마다 파라미터 업데이트시 전체 파라미터에 각 파라미터값의 나누기값을 계속해서 -를 해주어 영향이 큰 파라미터값을 작게하는 것이다. l1 정규화는 alpha값을 크게하면 아예 그 특성을 배재해버린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 훈련 세트에 있는 특성들이 아주 다른 스케일을 가지고 있다고 하자. 이런 데이터에 잘 작동하지 않는 회기 알고리즘은 무엇인가? 그 이유를 설명하고 이 문제를 해결할 방법을 제시하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 다음과 같이 사용해야 하는 이유를 설명하시오.\n",
    "* 1)규제가 없는 선형 모델 대신 릿지 회귀\n",
    "* 2)릿지 회귀 대신 라쏘 회귀\n",
    "* 3)라쏘 회귀 대신 엘라스틱넷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.사진을 낮과 밤, 실내와 실외로 분류하려 한다. 다음 중 어떤 분류기를 사용해야 하는 지 선택하고 그 이유를 설명하시오.\n",
    "* 1)두 개의 로지스틱 회귀 분류기\n",
    "* 2)소프트맥스 회귀 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Part2] 프로그램 문제 (파이썬 프로그램을 이용하여 다음 문제를 해결하시오.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. mglearn의 wave 데이터셋을 사용하여 다음 각각의 회귀 모델을 최대의 성능으로 학습시켜 모델의 성능을 비교하시오.\n",
    "* 1)선형 회귀 모델\n",
    "* 2)결정 트리 회귀 모델\n",
    "* 3)릿지 회귀 모델\n",
    "* 4)라쏘 회귀 모델\n",
    "\n",
    "wave 데이터셋은 다음과 같이 생성하시오.\n",
    "* wave 데이터셋의 샘플수는 200개로 하시오.\n",
    "* Y 훈련세트와 테스트세트는 'random_state =43'를 적용하여 분리하시오.\n",
    "결정트리 모델 ‘DecisionTreeRegressor’에서 옵션‘min_samples_split=3’를\n",
    "적용하시오.\n",
    "릿지와 라쏘 회귀 모델에서 의 변화에 따른 성능을 비교하시오. \n",
    "wave 데이터셋으로 모델을 만들고 numpy의 ‘linspace’로 1,000개의 x축 포인트를 담은 NumPy 배열 line을 만들어 모델의 예측값을 시각화하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. scikit-learn의 two_moon 데이터셋을 사용하여 RBF 커널 SVM 분류 모델를 학습시켜 훈련세트와 테스트세트의 성능을 비교하시오. \n",
    "two_moon데이터셋은 다음과 같이 샘플수 200개로 생성하시오.\n",
    "* 데이터셋은 다음과 같이 샘플수 200개로 생성하시오.'X, y = make_moons(n_smaples=200, noise=0.1, random_state=0'\n",
    "* 훈련세트와 테스트세트는 ‘random_state =43’를 적용하여 분리하시오\n",
    "* RBF 커널 SVM의 매개변수 C와  설정에 따른 결정 경계를 그래프로 시각화하시오."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
